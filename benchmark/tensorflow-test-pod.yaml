apiVersion: v1
kind: Pod
metadata:
  name: tensorflow-benchmark-pod
  namespace: default
  labels:
    app: tensorflow-benchmark
    test-type: migration-comparison
spec:
  containers:
  # Main TensorFlow training container (always running)
  - name: tensorflow-trainer
    image: tensorflow/tensorflow:2.13.0-gpu
    command: ["python", "-c"]
    args: 
    - |
      import tensorflow as tf
      import numpy as np
      import time
      import os
      
      print("=== TensorFlow Container Started ===")
      print(f"TensorFlow version: {tf.__version__}")
      print(f"GPU Available: {tf.config.list_physical_devices('GPU')}")
      
      # Create a simple model for continuous training
      model = tf.keras.Sequential([
          tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
          tf.keras.layers.Dropout(0.2),
          tf.keras.layers.Dense(10, activation='softmax')
      ])
      
      model.compile(optimizer='adam',
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])
      
      # Generate synthetic data for continuous training
      def generate_data():
          x = np.random.random((1000, 784))
          y = np.random.randint(10, size=(1000,))
          return x, y
      
      # Continuous training loop (simulates long-running AI workload)
      epoch = 0
      checkpoint_dir = '/migration-checkpoint'
      os.makedirs(checkpoint_dir, exist_ok=True)
      
      while True:
          try:
              x_train, y_train = generate_data()
              
              # Train for one epoch
              history = model.fit(x_train, y_train, epochs=1, verbose=1)
              
              # Save checkpoint every 5 epochs
              if epoch % 5 == 0:
                  checkpoint_path = f"{checkpoint_dir}/model_epoch_{epoch}.h5"
                  model.save_weights(checkpoint_path)
                  print(f"Checkpoint saved: {checkpoint_path}")
              
              epoch += 1
              
              # Simulate processing time
              time.sleep(10)
              
          except KeyboardInterrupt:
              print("Training interrupted")
              break
          except Exception as e:
              print(f"Training error: {e}")
              time.sleep(5)
    resources:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 2000m
        memory: 4Gi
    volumeMounts:
    - name: checkpoint-volume
      mountPath: /migration-checkpoint
    env:
    - name: CONTAINER_TYPE
      value: "running"
    - name: PYTHONUNBUFFERED
      value: "1"

  # Data preprocessing container (completes after processing)  
  - name: data-preprocessor
    image: tensorflow/tensorflow:2.13.0
    command: ["python", "-c"]
    args:
    - |
      import time
      import numpy as np
      import os
      
      print("=== Data Preprocessor Started ===")
      
      # Simulate data preprocessing (finite task)
      data_dir = '/migration-checkpoint/preprocessed_data'
      os.makedirs(data_dir, exist_ok=True)
      
      for i in range(10):
          # Simulate data processing
          data = np.random.random((1000, 784))
          filename = f"{data_dir}/batch_{i}.npy"
          np.save(filename, data)
          
          print(f"Processed batch {i+1}/10: {filename}")
          time.sleep(5)
      
      print("=== Data Preprocessing Completed ===")
      # This container will be in 'completed' state
    resources:
      requests:
        cpu: 200m
        memory: 512Mi  
      limits:
        cpu: 1000m
        memory: 2Gi
    volumeMounts:
    - name: checkpoint-volume
      mountPath: /migration-checkpoint
    env:
    - name: CONTAINER_TYPE
      value: "completed"

  # Model validator (runs periodically)
  - name: model-validator
    image: tensorflow/tensorflow:2.13.0
    command: ["python", "-c"] 
    args:
    - |
      import time
      import os
      import glob
      
      print("=== Model Validator Started ===")
      
      checkpoint_dir = '/migration-checkpoint'
      
      while True:
          try:
              # Check for model checkpoints
              checkpoints = glob.glob(f"{checkpoint_dir}/*.h5")
              
              if checkpoints:
                  latest_checkpoint = max(checkpoints, key=os.path.getctime)
                  print(f"Validating model: {latest_checkpoint}")
                  
                  # Simulate model validation
                  time.sleep(3)
                  print("Model validation completed successfully")
              else:
                  print("No checkpoints found for validation")
              
              # Wait before next validation
              time.sleep(30)
              
          except Exception as e:
              print(f"Validation error: {e}")
              time.sleep(10)
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi
    volumeMounts:
    - name: checkpoint-volume
      mountPath: /migration-checkpoint
    env:
    - name: CONTAINER_TYPE  
      value: "running"

  volumes:
  - name: checkpoint-volume
    persistentVolumeClaim:
      claimName: tensorflow-checkpoint-pvc
  
  # Schedule on a specific node for testing
  nodeSelector:
    kubernetes.io/arch: amd64
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: tensorflow-checkpoint-pvc
  namespace: default
  labels:
    app: tensorflow-benchmark
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: v1
kind: Service
metadata:
  name: tensorflow-benchmark-service
  namespace: default
  labels:
    app: tensorflow-benchmark
spec:
  selector:
    app: tensorflow-benchmark
  ports:
  - port: 8888
    targetPort: 8888
    name: jupyter
  - port: 6006  
    targetPort: 6006
    name: tensorboard
